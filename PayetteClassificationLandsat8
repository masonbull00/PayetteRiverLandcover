//This is the code for analyzing all of landsat 8 for the payette watershed
//It works nearly identically to the Nellie Juan Classifier, but there are some differences
//For more detail of what each line does, check out the Nellie Juan classifier on my Github (masonbull00)

//You will notice that there a lot of commented out 'print' commands. This code takes a while to run
////and printing when it is not necessary really slows it down. Start printing things if you are getting errors to
////see where they are occuring.

//You will need training data for the classes you are analyzing,
////a watershed outline and waterbodies shapfile,
///and a shapefile of the burned areas in the watershed

Map.setCenter(-115.0994, 44.1006, 12);
Map.setOptions({mapTypeId: 'HYBRID'});

// Add ROI and set your date to find imagery
var roi = ee.Geometry.Point(-115.0994, 44.1006); // study area
var date_i = '2012-06-01'; // set initial date (YYYY-MM-DD)
var date_f = '2023-10-31'; // Set final date (YYY-MM-DD)

//add an outline of the Payette Watershed to visualize the study area
var styling = {color: 'black', width: 4, fillColor: 'FF000000'};
Map.addLayer(pt_wtrshd.style(styling), null, 'pt_wtrshd');


///////////////////////////////////////////////////////////////
///////////Landsat 8 Workflow for the Payette//////////////
///////////////////////////////////////////////////////////////


// add landsat imagery, filter by cloud cover over land, only select spectral bands, and filter by roi and specified date range
var l8 = ee.ImageCollection("LANDSAT/LC08/C02/T1_L2")
  .filterDate(date_i, date_f)
  .filter(ee.Filter.calendarRange(8, 10, 'month'))
  .filterBounds(roi)
  .select( 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL')
  .filter(ee.Filter.lte('CLOUD_COVER_LAND', 25));
//print('l8', l8);

//this applies a QA bitmask to filter out pixels with excessive clouds and shadows
//this function is varied from Spatial Thoughts: https://spatialthoughts.com/2021/08/19/qa-bands-bitmasks-gee/
var qaFunc = function(image){
  var bitwiseExtract = function(input, fromBit, toBit) {
    var maskSize = ee.Number(1).add(toBit).subtract(fromBit);
    var mask = ee.Number(1).leftShift(maskSize).subtract(1);
    return input.rightShift(fromBit).bitwiseAnd(mask);
  };

  var qaBand = image.select('QA_PIXEL');
  var cirrus = bitwiseExtract(qaBand, 14, 15).neq(3);
  //var shadow = bitwiseExtract(qaBand, 10, 11).lte(2); shadow needs taken out as it is too aggressive with dark spots
  var cloud = bitwiseExtract(qaBand, 8, 9).neq(3);
  var bitMask = cirrus.and(cloud);
  return image.mask(bitMask);
};

var l8cloudFree = l8.map(qaFunc);
//print('l8 cloud free', l8cloudFree);

var cloudCount = function(image){
  var preMaskCount = image.reduceRegion({reducer: ee.Reducer.count(), geometry: pt_wtrshd.geometry(), scale: 30});
  return image.addBands(getNDSI).set('NDSIcount', pixelCount.get('NDSIth'));
};

var checkCRS = l8.first().projection().crs();
//print('l8 crs', checkCRS);

var checkProj = l8.first().projection();


//add a visualization parameter for the landsat imagery to display in the map if wanted
var l8visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 15000, gamma: [0.8, 0.8, 0.8]};

//add SRTM data, clip it to the the Payette, select only the elevation band, and then derive slope and aspect as separate images
var DEM = ee.Image("NASA/NASADEM_HGT/001").clip(pt_wtrshd.geometry()).select('elevation').reproject(checkProj);
var slope = ee.Terrain.slope(DEM);
var aspect = ee.Terrain.aspect(DEM);
//print('Elevation', DEM);
//print('Slope', slope);
//print('Aspect', aspect);

////export DEM data if needed
//Export.image.toDrive({
//  image: DEM,
//  description: 'PT_Elevation',
//  folder: 'Images',
//  fileNamePrefix: 'PT_Elevation',
//  scale: 30,
//  maxPixels: 9e7,
//  fileFormat: 'GeoTIFF',
//  region: pt_wtrshd.geometry(),
//  crs: 'EPSG:32606'});
//Export.image.toDrive({
//  image: slope,
//  description: 'PT_Slope',
//  folder: 'Images',
//  fileNamePrefix: 'PT_Slope',
//  scale: 30,
//  maxPixels: 9e7,
//  fileFormat: 'GeoTIFF',
//  region: pt_wtrshd.geometry(),
//  crs: 'EPSG:32606'});  
//Export.image.toDrive({
//  image: aspect,
//  description: 'PT_Aspect',
//  folder: 'Images',
//  fileNamePrefix: 'PT_Aspect',
//  scale: 30,
//  maxPixels: 9e7,
//  fileFormat: 'GeoTIFF',
//  region: pt_wtrshd.geometry(),
//  crs: 'EPSG:32606'});

var demClip = pt_wtrshd;

var oliBands = ['SR_B2',   'SR_B3',    'SR_B4',  'SR_B5',  'SR_B6',    'SR_B7'];
var defBands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2'];

var l8cor = l8cloudFree.select(oliBands, defBands);
//print('l8cor', l8cor);

//funtion to compute radians from degrees
function radians(img) {
  return img.toFloat().multiply(Math.PI).divide(180);}
//Get DEM Slope and Aspect in radians
var SLPrads = radians(slope);
var ASPrads = radians(aspect);

//function to do the terrain correction
var scscTCl8 = function(img) {
  var outImage = img.select([]);
  
  //Get the footprint image of the study area
  var footprint = ee.Geometry.Polygon(ee.Number(ee.List(img.get('system:footprint'))));

  //VARIABLES FROM METADATA
  var AZ = ee.Number(img.get('SUN_AZIMUTH'));
  var ZE = ee.Number(img.get('SUN_ELEVATION'));
  var AZ_R = radians(ee.Image(AZ));
  var ZE_R = radians(ee.Image(ZE));
  
  //CALCULATE LOCAL ILLUMINATION, COS OF THE SLOPE, AND COS OF THE ZENITH ANGLE
  var IL = AZ_R.subtract(ASPrads).cos().multiply(SLPrads.sin()).multiply(ZE_R.sin())
  .add(ZE_R.cos().multiply(SLPrads.cos()));
  var cos_ZE = ZE_R.cos();
  var cos_SLP = SLPrads.cos();
  

  //C for the blue band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultBlue = clippedImg.select('constant', 'constant_1', 'blue')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var blueC = (ee.Array(resultBlue.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultBlue.get('coefficients')).get([1,0]));
  var blueCorr = ((cos_ZE.multiply(cos_SLP)).add(blueC)).divide(IL.add(blueC));

  
  //C for the green band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultGreen = clippedImg.select('constant', 'constant_1', 'green')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var greenC = (ee.Array(resultGreen.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultGreen.get('coefficients')).get([1,0]));
  var greenCorr = ((cos_ZE.multiply(cos_SLP)).add(greenC)).divide(IL.add(greenC));
  
  //C for the red band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultRed = clippedImg.select('constant', 'constant_1', 'red')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var redC = (ee.Array(resultRed.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultRed.get('coefficients')).get([1,0]));
  var redCorr = ((cos_ZE.multiply(cos_SLP)).add(redC)).divide(IL.add(redC));
  
  //C for the nir band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultNir = clippedImg.select('constant', 'constant_1', 'nir')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var nirC = (ee.Array(resultNir.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultNir.get('coefficients')).get([1,0]));
  var nirCorr = ((cos_ZE.multiply(cos_SLP)).add(nirC)).divide(IL.add(nirC));
  
  //C for the swir1 band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultSwir1 = clippedImg.select('constant', 'constant_1', 'swir1')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var swir1C = (ee.Array(resultSwir1.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultSwir1.get('coefficients')).get([1,0]));
  var swir1Corr = ((cos_ZE.multiply(cos_SLP)).add(swir1C)).divide(IL.add(swir1C));
  
  //C for the swir2 band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultSwir2 = clippedImg.select('constant', 'constant_1', 'swir2')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var swir2C = (ee.Array(resultSwir2.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultSwir2.get('coefficients')).get([1,0]));
  var swir2Corr = ((cos_ZE.multiply(cos_SLP)).add(swir2C)).divide(IL.add(swir2C));
  
  //IMAGE CORRECTION
  var InImg2 = img.multiply(0.0001);
  
  var blueBand = InImg2.select('blue').multiply(blueCorr);
  //Map.addLayer(blueBand);
  var greenBand = InImg2.select('green').multiply(greenCorr);
  var redBand = InImg2.select('red').multiply(redCorr);
  var nirBand = InImg2.select('nir').multiply(redCorr);
  var swir1Band = InImg2.select('swir1').multiply(swir1Corr);
  var swir2Band = InImg2.select('swir2').multiply(swir2Corr);
  
  var img_TC = img.select().addBands([blueBand, greenBand, redBand, nirBand, swir1Band, swir2Band]);
  //print('img_TC', img_TC)
  
  //ADJUST VALUE RANGE (REFLECTANCE BETWEEN 0 AND 1)
  var img_TC1 = ((img_TC.multiply(10000)).int16());//.multiply(0.0001);
    
  outImage = outImage.addBands(img_TC1
  .select([0,1,2,3,4,5],['blue_TC', 'green_TC', 'red_TC', 'nir_TC', 'swir1_TC', 'swir2_TC']));
  return outImage;
};

var l8corCol = l8cor.map(scscTCl8);
//print('l8 corrected col', l8corCol);

var renameBands = function(image){
  return image.select(['blue_TC', 'green_TC', 'red_TC', 'nir_TC', 'swir1_TC', 'swir2_TC'])
  .rename(['B2', 'B3', 'B4', 'B5', 'B6', 'B7']);
};

var l8renamed = l8corCol.map(renameBands);
//print('RENAMED L8', l8renamed);

// create a function to clip each image in the image collection to the Payette
var clipping = function(image) {
  return image.clip(pt_wtrshd);
};

// Apply clipping function to l8 data
var l8_clip = l8renamed.map(clipping);
//print('l8 clipped', l8_clip);

// create a function to add the DEM elevation, slope, and aspect bands to the landsat images
var addDEM = function(image){
  return image.addBands(DEM).addBands(slope).addBands(aspect);
};

//apply the addDEM function to each image in the collection
var l8DEM = l8_clip.map(addDEM);
//print('l8 + DEM', l8DEM);

//create a water mask using NHD waterbodies polygons
var ptWaterImg = pt_water.reduceToImage(['fcode'], ee.Reducer.sum()).clip(pt_wtrshd.geometry());
var fireImg = fire.reduceToImage(['Shape_Area'], ee.Reducer.sum()).clip(pt_wtrshd.geometry());
var inverseFire = fireImg.not();
var inverseWater = ptWaterImg.not();

//create a function to apply the water mask to the composited imagery
var applyMask = function(image){
  var i = image.updateMask(inverseFire); 
  return i.updateMask(inverseWater);
};

//apply the water masking function to the composited imagery
var l8Masked = l8DEM.map(applyMask);
//print('Masked L8 Imagery', l8Masked);

//create a function to generate an NDSI and NDVI on the imagery
var createNDI = function(image){
  var NDSI = image.normalizedDifference(['B3', 'B6']).rename('NDSI');
  var NDVI = image.normalizedDifference(['B5', 'B4']).rename('NDVI');
  return image.addBands(NDSI).addBands(NDVI);
};

//apply the NDSI and NDVI creation function to the imagery
var l8NDI = l8Masked.map(createNDI);
//print('L8 + Idices', l8NDI);

//create a function to look over imagery and only select the most snow free images,
//this is to account for early snowfall and filter out those images with excess snow

//this function will count the number of snow free pixels
var NDSIth = function(image){
  var getNDSI = image.select('NDSI').gte(0.4).selfMask().rename('NDSIth');
  var pixelCount = getNDSI.reduceRegion({reducer: ee.Reducer.count(), geometry: pt_wtrshd.geometry(), scale: 30, bestEffort: true, maxPixels: 6700000});
  return image.addBands(getNDSI).set('NDSIcount', pixelCount.get('NDSIth'));
};

//map the function to get the count of pixels that are snow over the image collection
var l8SnowCount = l8NDI.map(NDSIth);
//print('l8 w snowy pixel count', l8SnowCount);

//this function will pass over the image collection and only keep images with a defined number of 
//snow free pixels
var l8SnowFree = l8SnowCount.filter(ee.Filter.lte('NDSIcount', 30000));
l8SnowFree = l8SnowFree.select('B2', 'B3', 'B4', 'B5', 'B6', 'B7', 
  'elevation', 'slope', 'aspect', 'NDSI', 'NDVI');
//print('l8 snow free images', l8SnowFree);

//create an empty list to add accuracies to after classification
var accuraciesL8 = ee.List([]);

//grab images for a single year from the snow free collection to make an image from for processing  
//using the new classificaiton technique, then get the median value of the imagery to get to a single 
//image, regardless of there being multiple images in a year
var composite2014 = l8SnowFree.filter(ee.Filter.date('2014-01-01', '2014-12-31')).median();
//print('2014 image composite', composite2014);
var composite2015 = l8SnowFree.filter(ee.Filter.date('2015-01-01', '2015-12-31')).median();
//print('2015 image composite', composite2015);
var composite2016 = l8SnowFree.filter(ee.Filter.date('2016-01-01', '2016-12-31')).median();
//print('2016 image composite', composite2016);
var composite2017 = l8SnowFree.filter(ee.Filter.date('2017-01-01', '2017-12-31')).median();
//print('2017 image composite', composite2017);
var composite2018 = l8SnowFree.filter(ee.Filter.date('2018-01-01', '2018-12-31')).median();
//print('2018 image composite', composite2018);
var composite2019 = l8SnowFree.filter(ee.Filter.date('2019-01-01', '2019-12-31')).median();
//print('2019 image composite', composite2019);
var composite2020 = l8SnowFree.filter(ee.Filter.date('2020-01-01', '2020-12-31')).median();
//print('2020 image composite', composite2020);
var composite2021 = l8SnowFree.filter(ee.Filter.date('2021-01-01', '2021-12-31')).median();
//print('2021 image composite', composite2021);
var composite2022 = l8SnowFree.filter(ee.Filter.date('2022-01-01', '2022-12-31')).median();
//print('2022 image composite', composite2022);
var composite2023 = l8SnowFree.filter(ee.Filter.date('2023-01-01', '2023-12-31')).median();
//print('2023 image composite', composite2023);


//Introduce Classes from 1986 layer for the classification. Classes are: 1: Rock, 2: Dense Forest,
//3: Transitional Forest, 4: Riparian Shrub, 5: Veg talus, 6: Tree Talus
//This class list includes water, but because we have a water mask this class can be removed
var classesNW = classes.filter(ee.Filter.inList('Class', [1, 2, 3, 4, 5, 6]));//.filter(
  //ee.Filter.lte('random', 0.8));

////////////////////
//You may find it helpful to play with the amount of training data you let into the classifier.
//I have that line commented out above, but play with it and see how/if your accuracy changes
///////////////////


//create a label for use in the classifier
var label = 'Class';

//define the important bands to use in the classification 
var bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'elevation',
  'slope', 'aspect', 'NDSI', 'NDVI'];
  
  
//This function will create training data for each image using the previously created split
//in the class data 
function classifyDataL8(image, points, year) {
  var trainingPoints = points.filter(ee.Filter.lte('random', 0.8));//<- if you change the amount of training data above you will need
  var validationPoints = points.filter(ee.Filter.gt('random', 0.8));// to adjust this to be 80% of however much data you allowed in
  
  var NDVI = image.select('NDVI');
  
  //sample the training data over the imagery
  var training = image.reduceRegions({
    collection: trainingPoints,
    reducer: ee.Reducer.first(),
    scale: 30
  }).filter(ee.Filter.neq('B1', null)).filter(ee.Filter.neq('B2', null))
  .filter(ee.Filter.neq('B3', null)).filter(ee.Filter.neq('B4', null))
  .filter(ee.Filter.neq('B5', null)).filter(ee.Filter.neq('B6', null))
  .filter(ee.Filter.neq('B7', null))
  .filter(ee.Filter.neq('NDVI', null)).filter(ee.Filter.neq('NDSI', null));
  
  //create and train an empty classifer
  var classifier = ee.Classifier.smileRandomForest(500)
  .train({
    features: training,
    classProperty: 'Class',
    inputProperties: image.bandNames()
  });
  
    //get classifier expanations
  var importance = ee.Dictionary(classifier.explain()
  .get('importance', 'outOfBagErrorEstimate'));
  
  //print('importance ' + year, importance);
  var totalImportance = importance.values().reduce(ee.Reducer.sum());
  
  var importancePercentage = importance.map(function (band, importance) {
  return ee.Number(importance).divide(totalImportance).multiply(100)}); 
  
  print('importance Percentage ' + year, importancePercentage);
  
  //classify the images
  var classifiedImage = image.classify(classifier);
  //print('classified Image '+ year, classifiedImage);
  
  var classedVisParams = {min: 1, max: 6, 
  'palette': ['45414E', '0E5B07', '16E810', '152AF5', '7D5108', 'ffd37f']
  };
  //add the classified layer to the map
  Map.addLayer(classifiedImage, classedVisParams, 'L8 ' + year, 0);
  
  //use the map to get accuracy metrics from validation data created earlier
  var testing = classifiedImage.sampleRegions({
    collection: validationPoints,
    properties: ['Class'],
    scale: 30,
    geometries: true
  });
  
    //find out which points are misclassified and display them
  var misclassified = testing.filter(ee.Filter.notEquals({ 
    leftField: 'Class', rightField: 'classification'
  }));
  
      
  var pointStyle = ee.Dictionary({
    1: {color: 'red', fillColor: '45414E', pointShape: 'circle', pointSize: 5},
    2: {color: 'red', fillColor: '0E5B07', pointShape: 'circle', pointSize: 5},
    3: {color: 'red', fillColor: '16E810', pointShape: 'circle', pointSize: 5},
    4: {color: 'red', fillColor: '152AF5', pointShape: 'circle', pointSize: 5},
    5: {color: 'red', fillColor: '7D5108', pointShape: 'circle', pointSize: 5},
    6: {color: 'red', fillColor: 'ffd37f', pointShape: 'circle', pointSize: 5}
  });
  
  misclassified = misclassified.map(function(feature){
    return feature.set('style', pointStyle.get(feature.get('Class')));
  });
  //print('Misclassified Points ' + year, misclassified);
  Map.addLayer(misclassified.style({styleProperty: 'style'}), {}, 'Misclassified Points ' + year, 0);
  
  //create a confusion matrix for the data
  var testingConfusionMatrix = testing.errorMatrix('Class', 'classification');
  //print the matrices
  print('confusion matrix l8 ' + year, testingConfusionMatrix);
  print('test accuracy l8 ' + year, testingConfusionMatrix.accuracy());
  //print('Users Accuracy '+year, testingConfusionMatrix.consumersAccuracy());
  //print('Producers Accuracy '+year, testingConfusionMatrix.producersAccuracy());
  //print('Kappa '+year, testingConfusionMatrix.kappa());
  
  var accuracy = testingConfusionMatrix.accuracy();
  accuraciesL8 = accuraciesL8.add(accuracy);

    
  var histo = ui.Chart.image.histogram({image: classifiedImage,
                                        region: pt_wtrshd.geometry(),
                                        scale: 30
                                          })//.setSeriesNames(['Rock', 'Dense Forest', 'Tran Forest', 'Riparian', 'Veg Talus', 'Tree Talus'])
  .setOptions({hAxis: {title: 'Class'}, 
  title: 'Count of Classification Occurence for '+year,
  colors: ['45414E', '0E5B07', '16E810', '152AF5', '7D5108', 'ffd37f']});
  print('class histogram ' + year, histo);
  
  //export the generate error matrix to Google Drive in a specified folder
  //(the matrix needs to be converted to a featureCollection first)
  //export the generated error matrix to Google Drive in a specified folder
  //(the matrix needs to be converted to a featureCollection first)
  
  ////this step converts the error matrix into an array, and then a callable feature
  //var exportMatrix = ee.Feature(null, {matrix: testingConfusionMatrix.array()});
  //Export.table.toDrive({
  //  collection: ee.FeatureCollection(exportMatrix),
  //  description: 'L8_Confusion_Matrix_for_' + year,
  //  folder: 'ErrorMatrix',
  //  fileNamePrefix: 'L8Matrix' + year,
  //  fileFormat: 'CSV'
  //});
  //
  ////export the feature of class areas 
  //Export.table.toDrive({
  //  collection: ee.FeatureCollection(classAreaFeature),
  //  description: 'L8_Classes_Areas_for_' + year,
  //  folder: 'ClassArea',
  //  fileNamePrefix: 'L8ClassArea' + year,
  //  fileFormat: 'CSV'
  //});
  //
  ////export imagery to google drive
  //Export.image.toDrive({
  //  image: classifiedImage,
  //  description: 'L8_FM_Classified_Image' + year,
  //  folder: 'PayetteGEEOutputs',
  //  fileNamePrefix: 'L8_PT_FM_ClassImg' + year,
  //  scale: 30,
  //  fileFormat: 'GeoTIFF',
  //  region: pt_wtrshd.geometry(),
  //  crs: 'EPSG:32611'
  //});
  //  //export ndvi to google drive
  //Export.image.toDrive({
  //  image: NDVI,
  //  description: 'L8_FM_NDVI' + year,
  //  folder: 'PayetteGEEOutputs',
  //  fileNamePrefix: 'L8_PTFM_NDVI' + year,
  //  scale: 30,
  //  maxPixels: 9e7,
  //  fileFormat: 'GeoTIFF',
  //  region: pt_wtrshd.geometry(),
  //  crs: 'EPSG:32611'
  //});
  ////Export a classified image to an asset
  //Export.image.toAsset({
  //  image: classifiedImage,
  //  description: 'classified' + year + 'toAsset',
  //  assetId: 'projects/boise-state-bull-thesis-work/assets/PT_FM_classified' + year,
  //  region: pt_wtrshd.geometry(),
  //  scale: 30,
  //  crs: 'EPSG:32611'
  //});

};


//run the classifier function on the composited imagery from each year,
//outputs an image on the map of the classification as well as a confusion
//matrix and accuracy in the console. Also adds in the corresponding year's Landsat image 
Map.addLayer(composite2014, l8visParams, 'Landsat 8 2014', 0);
classifyDataL8(composite2014, classesNW, '2014');
Map.addLayer(composite2015, l8visParams, 'Landsat 8 2015', 0);
classifyDataL8(composite2015, classesNW, '2015');
Map.addLayer(composite2016, l8visParams, 'Landsat 8 2016', 0);
classifyDataL8(composite2016, classesNW, '2016');
Map.addLayer(composite2017, l8visParams, 'Landsat 8 2017', 0);
classifyDataL8(composite2017, classesNW, '2017');
Map.addLayer(composite2018, l8visParams, 'Landsat 8 2018', 0);
classifyDataL8(composite2018, classesNW, '2018');
Map.addLayer(composite2019, l8visParams, 'Landsat 8 2019', 0);
classifyDataL8(composite2019, classesNW, '2019');
Map.addLayer(composite2020, l8visParams, 'Landsat 8 2020', 0);
classifyDataL8(composite2020, classesNW, '2020');
Map.addLayer(composite2021, l8visParams, 'Landsat 8 2021', 0);
classifyDataL8(composite2021, classesNW, '2021');
Map.addLayer(composite2022, l8visParams, 'Landsat 8 2022', 0);
classifyDataL8(composite2022, classesNW, '2022');
Map.addLayer(composite2023, l8visParams, 'Landsat 8 2023', 0);
classifyDataL8(composite2023, classesNW, '2023');

var listOfYearsL8 = ['2014', '2015', '2016', '2017', '2018', '2019','2020','2021', '2022', '2023'];
print('list of accuracies Landsat 8', accuraciesL8);
var accuracyChartL8 = ui.Chart.array.values({array: accuraciesL8, axis: 0, xLabels: listOfYearsL8})
                    .setOptions({title: 'Accuracy of Classification Over Time'});
print('accuracy chart L8', accuracyChartL8);

